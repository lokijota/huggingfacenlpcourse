{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if PyTorch with Cuda is installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA RTX A2000 Laptop GPU'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 01\n",
    "\n",
    "Tasks supported by pipelines:\n",
    "- feature-extraction (get the vector representation of a text)\n",
    "- fill-mask\n",
    "- ner (named entity recognition)\n",
    "- question-answering\n",
    "- sentiment-analysis\n",
    "- summarization\n",
    "- text-generation\n",
    "- translation\n",
    "- zero-shot-classification\n",
    "\n",
    "Doesn't seem to support\n",
    "- asking questions of text / extract insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# create a sentiment analysis pipeline\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455},\n",
       " {'label': 'POSITIVE', 'score': 0.7158698439598083},\n",
       " {'label': 'NEGATIVE', 'score': 0.967018723487854}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Curious as it also gets it right in portuguese\n",
    "classifier(\n",
    "    [\"I've been waiting for a HuggingFace course my whole life.\", \"I hate this so much!\", \"Isto é absolutamente adorável\", \"Isto é absolutamente horrível\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is a course about Covid-19 and life and death of humans under disease and pain',\n",
       " 'labels': ['tech', 'health', 'business', 'politics', 'sports'],\n",
       " 'scores': [0.5046038031578064,\n",
       "  0.28641557693481445,\n",
       "  0.10287082940340042,\n",
       "  0.060360126197338104,\n",
       "  0.04574966803193092]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# different task - zero shot classification\n",
    "# facebook/bart-large-mnli doesn't seem to do very well with this example\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "classifier(\n",
    "    \"This is a course about Covid-19 and life and death of humans under disease and pain\",\n",
    "    candidate_labels=[\"business\", \"health\", \"sports\", \"politics\", \"tech\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is a course about Covid-19 and life and death of humans under disease and pain',\n",
       " 'labels': ['health', 'tech', 'business', 'politics', 'sports'],\n",
       " 'scores': [0.44734638929367065,\n",
       "  0.22406303882598877,\n",
       "  0.12684054672718048,\n",
       "  0.1135772317647934,\n",
       "  0.0881727784872055]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying a different model\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"microsoft/deberta-xlarge-mnli\")\n",
    "classifier(\n",
    "    \"This is a course about Covid-19 and life and death of humans under disease and pain\",\n",
    "    candidate_labels=[\"business\", \"health\", \"sports\", \"politics\", \"tech\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'o meu chapéu tem três bicos',\n",
       " 'labels': ['portuguese',\n",
       "  'business',\n",
       "  'tech',\n",
       "  'french',\n",
       "  'sports',\n",
       "  'health',\n",
       "  'politics'],\n",
       " 'scores': [0.45083752274513245,\n",
       "  0.14250801503658295,\n",
       "  0.11888513714075089,\n",
       "  0.08598063141107559,\n",
       "  0.08276902139186859,\n",
       "  0.0782376080751419,\n",
       "  0.04078204929828644]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\n",
    "    \"o meu chapéu tem três bicos\",\n",
    "    candidate_labels=[\"business\", \"health\", \"sports\", \"politics\", \"tech\", \"french\", \"portuguese\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'The main reasons for Climate Change are complex and unpredictable. There is no simple solution.\\n\\nOur Climate Change problem may be a mystery to many, but we know what it is and we know what we are going to do about it. As long'}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the output changes on each generation and is generaly not good\n",
    "generator = pipeline(\"text-generation\") # , model=\"distilgpt2\")\n",
    "generator(\"The main reasons for Climate Change are\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"The best book ever written was written in the early 1950s by a man who, like all good novels, was a man who was a man.\\n\\nI think I could have written much better if I'd read a good book(s). I don't find them all that interesting. And I think all of the great books are those that I think are great books. My favorite is The\"},\n",
       " {'generated_text': 'The best book ever written was about this guy. He\\'s like a brother to me. I\\'ve been reading this book for more than five years now, and I never thought that I would end up reading it. I thought, \"Wow, somebody\\'s reading this book right now, and I\\'m going to be able to say, \\'Wow, I\\'m reading this book!\\'\"\\n\\nI\\'ve'}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the results suck both for the default gpt2 and distilgpt2\n",
    "generator = pipeline(\"text-generation\") #, model=\"distilgpt2\")\n",
    "generator(\n",
    "    \"The best book ever written was\",\n",
    "    max_length=80,\n",
    "    num_return_sequences=2,\n",
    "    temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilroberta-base and revision ec58a5b (https://huggingface.co/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'score': 0.18847587704658508,\n",
       "   'token': 1566,\n",
       "   'token_str': ' article',\n",
       "   'sequence': '<s>This article will teach you all about how women<mask>.</s>'},\n",
       "  {'score': 0.1335030496120453,\n",
       "   'token': 1040,\n",
       "   'token_str': ' book',\n",
       "   'sequence': '<s>This book will teach you all about how women<mask>.</s>'}],\n",
       " [{'score': 0.16272902488708496,\n",
       "   'token': 173,\n",
       "   'token_str': ' work',\n",
       "   'sequence': '<s>This<mask> will teach you all about how women work.</s>'},\n",
       "  {'score': 0.157148540019989,\n",
       "   'token': 18871,\n",
       "   'token_str': ' behave',\n",
       "   'sequence': '<s>This<mask> will teach you all about how women behave.</s>'}]]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only does one mask at a time\n",
    "unmasker = pipeline(\"fill-mask\") \n",
    "unmasker(\"This <mask> will teach you all about how women <mask>.\", top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.90422666,\n",
       "  'word': 'Josefina Varnafé',\n",
       "  'start': 19,\n",
       "  'end': 35},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.7157374,\n",
       "  'word': 'Setubalém',\n",
       "  'start': 50,\n",
       "  'end': 59},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.88490963,\n",
       "  'word': 'Blughab Grunhit',\n",
       "  'start': 63,\n",
       "  'end': 78}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decent results\n",
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "ner(\"My friends call me Josefina Varnafé and I work in Setubalém at Blughab Grunhit.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.982245147228241,\n",
       " 'start': 19,\n",
       " 'end': 35,\n",
       " 'answer': 'Josefina Varnafé'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answerer = pipeline(\"question-answering\")\n",
    "question_answerer(\n",
    "    question=\"What is my first name?\", #Where do I work?\n",
    "    context=\"My friends call me Josefina Varnafé and I work in Setubalém at Blughab Grunhit.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e89a16c356cf4954b7061189ef1068db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c0b985e2264f0781250a24db29626c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42a4d797c3d64a7fad7db92bef38fcf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a55c59a830a6484c9b3a6dbeccbf21ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b08cde62a17e4861ac53767b08b80db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' America has changed dramatically during recent years . The number of engineering graduates in the U.S. has declined in traditional engineering disciplines such as mechanical, civil,    electrical, chemical, and aeronautical engineering . Rapidly developing economies such as China and India continue to encourage and advance the teaching of engineering .'}]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\") # most popular is facebook/bart-large-cnn\n",
    "summarizer(\n",
    "    \"\"\"\n",
    "    America has changed dramatically during recent years. Not only has the number of \n",
    "    graduates in traditional engineering disciplines such as mechanical, civil, \n",
    "    electrical, chemical, and aeronautical engineering declined, but in most of \n",
    "    the premier American universities engineering curricula now concentrate on \n",
    "    and encourage largely the study of engineering science. As a result, there \n",
    "    are declining offerings in engineering subjects dealing with infrastructure, \n",
    "    the environment, and related issues, and greater concentration on high \n",
    "    technology subjects, largely supporting increasingly complex scientific \n",
    "    developments. While the latter is important, it should not be at the expense \n",
    "    of more traditional engineering.\n",
    "\n",
    "    Rapidly developing economies such as China and India, as well as other \n",
    "    industrial countries in Europe and Asia, continue to encourage and advance \n",
    "    the teaching of engineering. Both China and India, respectively, graduate \n",
    "    six and eight times as many traditional engineers as does the United States. \n",
    "    Other industrial countries at minimum maintain their output, while America \n",
    "    suffers an increasingly serious decline in the number of engineering graduates \n",
    "    and a lack of well-educated engineers.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \" In Blindness by Jose Saramago, a Portuguese writer deals with a mysterious mass plague of blindness that affects nearly everyone living in an unnamed place in a never specified time . With gorgeous prose, this thought-provoking book shows us how our world, ever so concerned and consumed by appearances, would deal with the loss of our most relied upon sense: vision . The scenes that follow are extremely unpleasant to read, but at the same time they're so realistic that you can’t be mad .\"}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(\n",
    "    \"\"\"\n",
    "    Blindness is a great novel by Portuguese writer José Saramago that deals with human’s individual and collective reactions when in the face of adversarial forces. With gorgeous prose, this thought-provoking book shows us how our world, ever so concerned and consumed by appearances, would deal with the loss of our most relied upon sense: vision. When it’s every man by himself, when every man is free to do whatever he wants without the impending fear of recognition and judgement, we start to feel – I was going to say see – what the man’s true nature is and the crumbling down of a civilization diseased with selfishness, intolerance and ambition, to name just few symptoms.\n",
    "    In Blindness by Jose Saramago, authortells us the story of a mysterious mass plague of blindness that affects nearly everyone living in an unnamed place in a never specified time and the implications this epidemic has on people’s lives. It all starts inexplicably when a man in his car suddenly starts seeing – or rather stops seeing anything but – a clear white brightness. He’s blind. Depending upon a stranger’s kindness to be able to go home in safety, we witness what appears to be the first sign of corruption and the first crack in society’s impending breakdown when the infamous volunteer steals the blind man’s car. Unfortunately for him, the white pest follows him and turns him into one of its victims as well.\n",
    "    Spreading fast, this collective blindness is now frightening the authorities and must be dealt with: a large group of blind people and possibly infected ones – those who had any contact with the first group – have now been put in quarantine until second order. Living conditions start to degrade as the isolated population grows bigger, there is no organization, basic medicine is a luxury not allowed in and hygiene is nowhere to be found. To complicate things further, an armed clique acquires control and power, forcing the subjugated to pay for food in any way they can. The scenes that follow are extremely unpleasant to read, but at the same time they’re so realistic that you can’t be mad at Saramago for writing such severe events packed with violence that include rapes and murders.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'Este curso faith feito pela Hugging Face.'}]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
    "translator(\"Ce cours est produit par Hugging Face.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:14:42] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 21:14:42] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 21:14:42] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 21:14:42] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 21:14:42] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon WARNING @ 21:14:44] We saw that you have a 11th Gen Intel(R) Core(TM) i7-11370H @ 3.30GHz but we don't know it. Please contact us.\n",
      "[codecarbon INFO @ 21:14:44] CPU Model on constant consumption mode: 11th Gen Intel(R) Core(TM) i7-11370H @ 3.30GHz\n",
      "[codecarbon INFO @ 21:14:44] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 21:14:44]   Platform system: Windows-10-10.0.22621-SP0\n",
      "[codecarbon INFO @ 21:14:44]   Python version: 3.9.16\n",
      "[codecarbon INFO @ 21:14:44]   Available RAM : 31.838 GB\n",
      "[codecarbon INFO @ 21:14:44]   CPU count: 8\n",
      "[codecarbon INFO @ 21:14:44]   CPU model: 11th Gen Intel(R) Core(TM) i7-11370H @ 3.30GHz\n",
      "[codecarbon INFO @ 21:14:44]   GPU count: 1\n",
      "[codecarbon INFO @ 21:14:44]   GPU model: 1 x NVIDIA RTX A2000 Laptop GPU\n",
      "c:\\Users\\joamart\\Anaconda3\\envs\\hfnlp\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\joamart\\Anaconda3\\envs\\hfnlp\\lib\\site-packages\\transformers\\generation\\utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "[codecarbon INFO @ 21:14:52] Energy consumed for RAM : 0.000015 kWh. RAM Power : 11.939220428466797 W\n",
      "[codecarbon INFO @ 21:14:52] Energy consumed for all GPUs : 0.000004 kWh. All GPUs Power : 3.338 W\n",
      "[codecarbon INFO @ 21:14:52] Energy consumed for all CPUs : 0.000055 kWh. All CPUs Power : 42.5 W\n",
      "[codecarbon INFO @ 21:14:52] 0.000075 kWh of electricity used since the begining.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'Parfois, je ressemble à une banane courbée jaune remplie de miel.'}]\n",
      "Emissions: 0.022567390403866433 g\n"
     ]
    }
   ],
   "source": [
    "# modelo suporta 4 idiomas (en/de/fr/ro) e pode ser usado também para tarefas como sumarização\n",
    "# notar como especificar o idioma de entrada e de saída\n",
    "from codecarbon import EmissionsTracker\n",
    "\n",
    "tracker = EmissionsTracker()\n",
    "tracker.start()\n",
    "translator = pipeline(\"translation_en_to_fr\", model=\"t5-base\")\n",
    "print(translator(\"Sometimes I look like a yellow curved banana filled with honey.\", max_length=40))\n",
    "\n",
    "# tracker.stop()\n",
    "emissions: float = tracker.stop()\n",
    "print(f\"Emissions: {emissions*1000} g CO2\")\n",
    "\n",
    "# good read on t5 and transformers - https://github.com/christianversloot/machine-learning-articles/blob/main/easy-machine-translation-with-machine-learning-and-huggingface-transformers.md\n",
    "# and the full list of articles - https://github.com/christianversloot/machine-learning-articles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias and Limitations\n",
    "\n",
    "These models are often trained e.g. on biased text, and it shows in their outputs.\n",
    "\n",
    "«When asked to fill in the missing word in these two sentences, the model gives only one gender-free answer (waiter/waitress). The others are work occupations usually associated with one specific gender — and yes, **prostitute** ended up in the top 5 possibilities the model associates with “woman” and “work.” *This happens **even though** BERT is one of the rare Transformer models not built by scraping data from all over the internet, but rather using apparently neutral data (it’s trained on the English Wikipedia and BookCorpus datasets)*.\n",
    "\n",
    "«You therefore need to keep in the back of your mind that the original model you are using could very easily generate sexist, racist, or homophobic content. **Fine-tuning the model on your data won’t make this intrinsic bias disappear**.»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb65a8afc7344e182a659bd44bb6603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e6e403e4aa43058f56e55a7dd6d30c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dbd20b147874b65b9eb46403760608e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08f6738471bb4571adea857120ec9fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3f3b8553b154215b7de633381a5f2bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['carpenter', 'lawyer', 'farmer', 'businessman', 'doctor']\n",
      "['nurse', 'maid', 'teacher', 'waitress', 'prostitute']\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "unmasker = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
    "result = unmasker(\"This man works as a [MASK].\")\n",
    "print([r[\"token_str\"] for r in result])\n",
    "\n",
    "result = unmasker(\"This woman works as a [MASK].\")\n",
    "print([r[\"token_str\"] for r in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hfnlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
